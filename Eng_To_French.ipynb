{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanchitkripalani47/Data-Science/blob/main/Eng_To_French.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6071d1c6",
      "metadata": {
        "id": "6071d1c6"
      },
      "source": [
        "## English to French Translation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "32276968",
      "metadata": {
        "id": "32276968"
      },
      "outputs": [],
      "source": [
        "# Import Numpy library\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount the Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WptuU7dYujpd",
        "outputId": "302412a9-5412-4968-cbd5-49fd4957747a"
      },
      "id": "WptuU7dYujpd",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "117d124d",
      "metadata": {
        "id": "117d124d"
      },
      "outputs": [],
      "source": [
        "# Read the data\n",
        "# The data is present in the form of txt file with line by line separation\n",
        "\n",
        "filepath = '/content/drive/MyDrive/Datasets/eng_to_french.txt'\n",
        "\n",
        "raw_text = open(filepath, encoding='utf-8').read().split('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "39def8c3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39def8c3",
        "outputId": "44586c24-19c6-49f9-cf5a-cd71db7b0c28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "145437\n"
          ]
        }
      ],
      "source": [
        "# Print the number of lines/translations in the dataset\n",
        "print(len(raw_text))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9f2cf60",
      "metadata": {
        "id": "e9f2cf60"
      },
      "source": [
        "We will use 10,000 samples for this task. Also, we need to preprocess the text by adding tokens in the english and french sentences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "d9140ac0",
      "metadata": {
        "id": "d9140ac0"
      },
      "outputs": [],
      "source": [
        "# Text Preprocessing\n",
        "\n",
        "num_samples = 10000\n",
        "\n",
        "# Storing eng and french sentences \n",
        "eng_sents = []\n",
        "fre_sents = []\n",
        "\n",
        "# Storing eng and french characters\n",
        "eng_chars = set()\n",
        "fre_chars  = set()\n",
        "\n",
        "\n",
        "# Process the sentences\n",
        "for i in range(num_samples):\n",
        "    eng_sent = str(raw_text[i].split('\\t'))[0]\n",
        "    \n",
        "    # The target text must have start and end tokens, \n",
        "    # which is needed in the decoder part. '\\t' is used for start and '\\n' for end. \n",
        "    fre_sent = '\\t' + str(raw_text[i]).split('\\t')[1] + '\\n'\n",
        "    \n",
        "    # Adding all the sentences in the lists\n",
        "    eng_sents.append(eng_sent)\n",
        "    fre_sents.append(fre_sent)\n",
        "    \n",
        "    # Adding all unique characters using sets\n",
        "    for ch in eng_sent:\n",
        "        eng_chars.add(ch)\n",
        "        \n",
        "    for ch in fre_sent:\n",
        "        fre_chars.add(ch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "2937f36f",
      "metadata": {
        "id": "2937f36f"
      },
      "outputs": [],
      "source": [
        "# Sort the characters\n",
        "eng_chars = sorted(list(eng_chars))\n",
        "fre_chars = sorted(list(fre_chars))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "a26d632e",
      "metadata": {
        "id": "a26d632e"
      },
      "outputs": [],
      "source": [
        "# Using dictionaries to store index to characters and visa versa\n",
        "\n",
        "# For english index to char\n",
        "eng_index_to_char = {}\n",
        "\n",
        "# For english char to index\n",
        "eng_char_to_index = {}\n",
        "\n",
        "# For french index to char\n",
        "fre_char_to_index = {}\n",
        "\n",
        "# For french char to index\n",
        "fre_index_to_char = {}\n",
        "\n",
        "for key, value in enumerate(eng_chars):\n",
        "    eng_index_to_char[key] = value\n",
        "    eng_char_to_index[value] = key\n",
        "    \n",
        "for key, value in enumerate(fre_chars):\n",
        "    fre_index_to_char[key] = value\n",
        "    fre_char_to_index[value] = key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "ec23aa8b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec23aa8b",
        "outputId": "cbecc71e-1cd1-4a93-e289-b97b444c8b6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The maximum length of an English sentence here is: 1\n",
            "The maximum length of a French sentence here is: 59\n"
          ]
        }
      ],
      "source": [
        "# Get the maximum length of english and french sentences\n",
        "max_len_eng = max([len(i) for i in eng_sents])\n",
        "max_len_fre = max([len(i) for i in fre_sents])\n",
        "\n",
        "print(f'The maximum length of an English sentence here is: {max_len_eng}')\n",
        "print(f'The maximum length of a French sentence here is: {max_len_fre}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "bf2475a7",
      "metadata": {
        "id": "bf2475a7"
      },
      "outputs": [],
      "source": [
        "# Preparing a one-hot encoding for the sentences \n",
        "\n",
        "tokenized_eng_sents = np.zeros(shape=(num_samples, max_len_eng, len(eng_chars)), dtype='float32')\n",
        "tokenized_fre_sents = np.zeros(shape=(num_samples, max_len_fre, len(fre_chars)), dtype='float32')\n",
        "target_data = np.zeros(shape=(num_samples, max_len_fre, len(fre_chars)), dtype='float32')\n",
        "\n",
        "# Here \n",
        "# 1D = num_samples, 2D = Max len of language, 3D = Total characters in language"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "226d45c1",
      "metadata": {
        "id": "226d45c1"
      },
      "outputs": [],
      "source": [
        "# Vectorize the english and french sentences\n",
        "\n",
        "for i in range(num_samples):\n",
        "    for key, char in enumerate(eng_sents[i]):\n",
        "        tokenized_eng_sents[i, key, eng_char_to_index[char]] = 1\n",
        "        \n",
        "    for key, char in enumerate(fre_sents[i]):\n",
        "        tokenized_fre_sents[i, key, fre_char_to_index[char]] = 1\n",
        "    \n",
        "        # The target data for decoder will be ahead by one timestamp \n",
        "        # And it will not include the start character.\n",
        "        if key > 0:\n",
        "            target_data[i, key-1, fre_char_to_index[char]] = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4626eaa",
      "metadata": {
        "id": "d4626eaa"
      },
      "source": [
        "### Modelling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "051de4aa",
      "metadata": {
        "id": "051de4aa"
      },
      "outputs": [],
      "source": [
        "# Import necessary tensorflow libraries for creating the model\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "c255dde2",
      "metadata": {
        "id": "c255dde2"
      },
      "outputs": [],
      "source": [
        "# Encoder model\n",
        "\n",
        "enc_ip = Input(shape=(None, len(eng_chars)))\n",
        "# Note here that only the end state is returned and not all the sequences\n",
        "enc_LSTM = LSTM(256, return_state=True)\n",
        "enc_op, enc_h, enc_c = enc_LSTM(enc_ip)\n",
        "enc_states = [enc_h, enc_c]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "61224278",
      "metadata": {
        "id": "61224278"
      },
      "outputs": [],
      "source": [
        "# Decoder model\n",
        "\n",
        "dec_ip = Input(shape=(None, len(fre_chars)))\n",
        "# Note here that we output both, all the sequences as well as the final state\n",
        "dec_LSTM = LSTM(256, return_sequences=True, return_state=True)\n",
        "dec_out, _, _ = dec_LSTM(dec_ip, initial_state=enc_states)\n",
        "dec_dense = Dense(len(fre_chars), activation='softmax')\n",
        "dec_out = dec_dense(dec_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "5f059fca",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f059fca",
        "outputId": "99e0c6a5-9fa9-43a2-fcb5-234e5bba4f58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "125/125 [==============================] - 45s 339ms/step - loss: 1.0974 - val_loss: 1.2104\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 42s 336ms/step - loss: 1.0121 - val_loss: 1.1747\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 41s 331ms/step - loss: 0.9615 - val_loss: 1.1077\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 40s 324ms/step - loss: 0.9220 - val_loss: 1.0880\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 41s 325ms/step - loss: 0.8844 - val_loss: 1.0547\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 41s 326ms/step - loss: 0.8549 - val_loss: 1.0062\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 41s 326ms/step - loss: 0.8314 - val_loss: 1.0229\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 41s 329ms/step - loss: 0.8126 - val_loss: 0.9901\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 41s 329ms/step - loss: 0.7956 - val_loss: 0.9724\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 41s 326ms/step - loss: 0.7817 - val_loss: 0.9445\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3e1d06ab10>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "# Combining both the models\n",
        "model = Model(inputs=[enc_ip, dec_ip], outputs=[dec_out])\n",
        "\n",
        "# Run training \n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
        "\n",
        "# Fit the model\n",
        "model.fit(x=[tokenized_eng_sents, tokenized_fre_sents],\n",
        "          y=target_data,\n",
        "          batch_size=64,\n",
        "          epochs=10,\n",
        "          validation_split=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing The Model"
      ],
      "metadata": {
        "id": "hZoFp1PgygLi"
      },
      "id": "hZoFp1PgygLi"
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference model for testing\n",
        "\n",
        "# For Encoder\n",
        "enc_model_inf = Model(enc_ip, enc_states)\n",
        "\n",
        "# For Decoder\n",
        "dec_state_ip_h = Input(shape=(256,))\n",
        "dec_state_ip_c = Input(shape=(256,))\n",
        "dec_ip_states = [dec_state_ip_h, dec_state_ip_c]\n",
        "\n",
        "dec_out, dec_h, dec_c = dec_LSTM(dec_ip, initial_state=dec_ip_states)\n",
        "\n",
        "dec_states = [dec_h, dec_c]\n",
        "dec_out = dec_dense(dec_out)\n",
        "\n",
        "dec_model_inf = Model(inputs=[dec_ip]+dec_ip_states,\n",
        "                      outputs=[dec_out]+dec_states)"
      ],
      "metadata": {
        "id": "5pX0jOT8wuxW"
      },
      "id": "5pX0jOT8wuxW",
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_seq(ip_seq):\n",
        "\n",
        "    # Intial State value will come from encoder\n",
        "    states_val = enc_model_inf.predict(ip_seq)\n",
        "\n",
        "    target_seq = np.zeros((1,1,len(fre_chars)))\n",
        "    target_seq[0,0,fre_char_to_index['\\t']] = 1\n",
        "\n",
        "    translated_sent = ''\n",
        "    toStop = False\n",
        "\n",
        "    while not toStop:\n",
        "        dec_out, dec_h, dec_c = dec_model_inf.predict(x=[target_seq]+states_val)\n",
        "\n",
        "        max_val_index = np.argmax(dec_out[0,-1,:])\n",
        "        sampled_fre_char = fre_index_to_char[max_val_index]\n",
        "        translated_sent += sampled_fre_char\n",
        "\n",
        "        if ((sampled_fre_char == '\\n')  or (len(translated_sent) > max_len_fre)):\n",
        "            toStop = True\n",
        "\n",
        "        target_seq = np.zeros((1,1,len(fre_chars)))\n",
        "        target_seq[0,0,max_val_index] = 1\n",
        "\n",
        "        states_val = [dec_h, dec_out]\n",
        "\n",
        "    return translated_sent"
      ],
      "metadata": {
        "id": "I7pVnZhlzupd"
      },
      "id": "I7pVnZhlzupd",
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for seq_index in range(10):\n",
        "    ip_seq = tokenized_eng_sents[seq_index:seq_index+1]\n",
        "    translated_sent = decode_seq(ip_seq)\n",
        "    print('-')\n",
        "    print('English Sentence: ', eng_sent[seq_index])\n",
        "    print('French Sentence: ', translated_sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 640
        },
        "id": "fEdKO7441jPL",
        "outputId": "6ac51b9c-0f4d-4681-ead0-f038ff184204"
      },
      "id": "fEdKO7441jPL",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-eb1f7e4cfdeb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mseq_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mip_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenized_eng_sents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseq_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mseq_index\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtranslated_sent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mip_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'English Sentence: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meng_sent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseq_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-16e712987b1a>\u001b[0m in \u001b[0;36mdecode_seq\u001b[0;34m(ip_seq)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtoStop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mdec_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdec_model_inf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_seq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstates_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mmax_val_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 2 of layer \"model_6\" is incompatible with the layer: expected shape=(None, 256), found shape=(None, 1, 93)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "k604-IIP2M07"
      },
      "id": "k604-IIP2M07",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "Eng_To_French.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}